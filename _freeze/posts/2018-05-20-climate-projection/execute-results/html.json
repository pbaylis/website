{
  "hash": "a73983a65cafb1c6425d1050d24bbfa4",
  "result": {
    "markdown": "---\ntitle: Climate Projection Sandbox\ndate: \"2018-05-20\"\nauthor: Patrick Baylis\ncategories:\n  - econometrics\ntags:\n  - R\n  - climate\n  - projection\ntoc: true\n---\n\n\n\n\nMany climate-society papers project the impacts of predicted climate change on the outcome of interest (guilty!). This post include code to conduct this kind of \"climate projection exercise\". The idea is to combine a dose-response function $f(T)$ (i.e., a damage function) with an estimate of the projected shift in the distribution of climate $\\Delta g(T)$. Specifically, damages are:\n$$ \\int^T f(t) \\Delta g(t) dt $$\n\nHowever, we'll be estimating this integral numerically, because $f(T)$ is annoying to integrate analytically and $g(T)$ will be projected numerically. More on that later. First, import some packages\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(data.table) # data munging\nlibrary(ggplot2) # plotting\nlibrary(splines) # bsplines for spline estimation\nlibrary(survey) # svycontrast for prediction\nlibrary(lfe) # high dimensional FE \nlibrary(scales) # transparency\n```\n:::\n\n\nSimulate a mostly-but-not-entirely increasing sinusoidal dose-response function, where $y$ is some outcome we care about that is affected (in a weird way) by temperature.\n\n::: {.cell hash='2018-05-20-climate-projection_cache/html/dgp_02f5ef66b89d92b3a03c45eeb501ba5b'}\n\n```{.r .cell-code}\nset.seed(42)\nN <- 1000 \ndt <- data.table(T = runif(N, 0, 40))\ndt[, y := -10 + 0.5 * T + 8 * sin(T / 6) + rnorm(N)]\n\nggplot(data = dt, aes(x = T, y = y)) + geom_point() + theme_minimal()\n```\n\n::: {.cell-output-display}\n![](2018-05-20-climate-projection_files/figure-html/dgp-1.png){width=672}\n:::\n:::\n\n\n# Estimate damage function\nSince we normally wouldn't know the exact functional form of the DGP, we'll estimate $f(T)$ with a b-spline. If you haven't used splines before or just need a refresher, see this handy [reference](http://people.stat.sfu.ca/~cschwarz/Consulting/Trinity/Phase2/TrinityWorkshop/Workshop-material-Simon/Intro_to_splines/intro_to_splines_notes.pdf) on using splines, and specifically why b-splines are attractive in a regression model. We'll use a cubic spline with knots at the internal quartiles.\n\n\n::: {.cell hash='2018-05-20-climate-projection_cache/html/estimate-f_6830aae849883d184f2e4cfd2989bb53'}\n\n```{.r .cell-code}\nknots <- quantile(dt$T, probs = c(0.25, 0.5, 0.75))\nboundary <- range(dt$T); degree = 3; intercept = TRUE\nX <- ns(dt$T, knots = knots, Boundary.knots = boundary, intercept=intercept)\n\n# Estimate with both felm and lm to demonstrate\nfit <- felm(y ~ X - 1, data = dt)\nlmfit <- lm(y ~ X - 1, data = dt)\n```\n:::\n\n\n# Generate climate predictions\nGenerate some climate predictions. Normally you'd do this by combining the output from a climate model - see Auffhammer et al (2014) for details on how to do this - but today we'll just take the realized \"weather\" from above and increase it by 5 on average. Construct a sequence of equally spaced intervals that includes the range of observed and predicted temperature and create basis vectors for both. Then estimate the PDFs of the current and future distributions and take the difference between them as $\\Delta g(T)$. \n\n\n::: {.cell hash='2018-05-20-climate-projection_cache/html/climpred_f750bcd699a849d9c7e3599b220519a2'}\n\n```{.r .cell-code}\ndt[, T_future := T + rnorm(N, 5, 5)]\n\nwidth <- 1 # Set interval for prediction: lower values = more precision (diminishing returns here)\ns <- seq(min(dt[, list(T, T_future)]), max(dt[, list(T, T_future)]), width) \n\n# Could use a histogram instead of a PDF here\ndensities <- data.table(s = s, \n                        cur_density = approxfun(density(dt$T))(s),\n                        fut_density = approxfun(density(dt$T_future))(s))\ndensities[is.na(cur_density), cur_density := 0]\ndensities[is.na(fut_density), fut_density := 0]\ndensities[, diff_density := fut_density - cur_density] \n\nggplot(data = melt(densities, id.vars = \"s\"), aes(x = s, y = value, colour = variable, group = variable)) + \n  geom_line() + theme_minimal()\n```\n\n::: {.cell-output-display}\n![](2018-05-20-climate-projection_files/figure-html/climpred-1.png){width=672}\n:::\n:::\n\n\n\n# Predict along interval\n\n\n\n::: {.cell hash='2018-05-20-climate-projection_cache/html/predict0_c8725b6309638e181e1c2b062e5074c0'}\n\n```{.r .cell-code}\nXp <- ns(s, knots = knots, Boundary.knots = boundary, intercept=intercept)\ncolnames(Xp) <- paste0(\"X\", colnames(Xp))\n```\n:::\n\n\n## Predict from felm output with `svycontrast`\nPredict over the sequence using `survey::svycontrast`. This works with both `lm` and `felm`.\n\n\n::: {.cell hash='2018-05-20-climate-projection_cache/html/predict1_69808fc7b09e8e84d61cdd1374af3356'}\n\n```{.r .cell-code}\nres.list <- list()\nfor (i in 1:nrow(Xp)) {\n  this.x <- s[i]\n  this.row <- c(unlist(Xp[i, ])) # Sometimes, will need to fill in values for other covariates (0s or means?), e.g. ppt\n  temp.dt <- as.data.table(svycontrast(fit, this.row))\n  temp.dt[, x:=this.x]\n  setnames(temp.dt, c(\"coef\", \"se\", \"x\"))\n  res.list[[as.character(this.x)]] <- temp.dt\n}\nresult_survey <- rbindlist(res.list)\n\nggplot(data = result_survey, aes(x = x, y = coef)) + \n  geom_point(data = dt, mapping = aes(x = T, y = y), colour = \"blue\", alpha = 0.5) +\n  geom_line() +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](2018-05-20-climate-projection_files/figure-html/predict1-1.png){width=672}\n:::\n:::\n\n\n## Predict from lm output with `predict`\nAlternative to usingy `survey::svycontrast` loop is to do the same using `predict.lm`, but there is no equivalent `predict.felm`. \n\n::: {.cell hash='2018-05-20-climate-projection_cache/html/predict2_1b725e132b7b09bc632c297fd0616e41'}\n\n```{.r .cell-code}\n# Note the list notation here. Need to tell predict that Xp is replacing X o\nresult_predict <- as.data.table(predict(lmfit, newdata = list(X = Xp), se.fit = T))\nresult_predict[, s := s]\nggplot(data = result_predict, aes(x = s, y = fit)) + \n  geom_point(data = dt, mapping = aes(x = T, y = y), colour = \"blue\", alpha = 0.5) +\n  geom_line() +\n  theme_minimal() \n```\n\n::: {.cell-output-display}\n![](2018-05-20-climate-projection_files/figure-html/predict2-1.png){width=672}\n:::\n:::\n\n\n# Compute damages\nFinally, compute damages: $\\sum^T f(T) \\times \\Delta g(T) \\times \\text{interval width}$.\n\n\n::: {.cell hash='2018-05-20-climate-projection_cache/html/computedamages_54de2746f593c5c91e014ee8caefc1d1'}\n\n```{.r .cell-code}\nf <- result_survey$coef\ng <- densities$diff_density\n\nsum(f * g * width)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 3.370896\n```\n:::\n:::\n\n\nNote that the interpretation of this sum is that it is the amount of damage _at the given observational unit_ for this amount of climate change. So if this is a regression of, say, daily crimes in a county on temperature, then the implication is the given amount of climate change will result in this many more crimes per county per day on average. Of course, this relies on the usual assumptions about the extrapolation of the results from weather regressions to climate effects.\n\nSubstitute in different damage functions $f(T)$ to show, for example, how different choices of fixed effects change the output. Substitute in different climate projections $\\Delta g(T)$ to show damages by region, over time, by region over time, et cetera.\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}